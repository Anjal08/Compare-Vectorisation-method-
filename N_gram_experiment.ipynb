{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORFnH4zjRUJOsQiyyHjyad",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anjal08/Compare-Vectorisation-method-/blob/main/N_gram_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "positive_sentences = [\n",
        "    \"I love this movie\",\n",
        "    \"The podcast was really informative\",\n",
        "    \"Great storyline and amazing acting\",\n",
        "    \"This episode was very helpful\",\n",
        "    \"I enjoyed every minute\",\n",
        "]\n",
        "\n",
        "negative_sentences = [\n",
        "    \"I hated this movie\",\n",
        "    \"The podcast was boring\",\n",
        "    \"Very bad storyline and poor acting\",\n",
        "    \"This episode was not helpful\",\n",
        "    \"I did not enjoy this at all\",\n",
        "]\n",
        "\n",
        "data = []\n",
        "for _ in range(5000):\n",
        "    data.append([random.choice(positive_sentences), 1])  # Positive\n",
        "    data.append([random.choice(negative_sentences), 0])  # Negative\n",
        "\n",
        "df = pd.DataFrame(data, columns=[\"text\", \"label\"])\n",
        "\n",
        "df.head(), len(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzCiT2RcD31J",
        "outputId": "1c768e5c-6e59-4890-c61a-99f30d9f6f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                 text  label\n",
              " 0  Great storyline and amazing acting      1\n",
              " 1              The podcast was boring      0\n",
              " 2       This episode was very helpful      1\n",
              " 3  Very bad storyline and poor acting      0\n",
              " 4                   I love this movie      1,\n",
              " 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df[\"text\"]\n",
        "y = df[\"label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "ntPudJIqD_C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "cv = CountVectorizer()\n",
        "X_train_cv = cv.fit_transform(X_train)\n",
        "X_test_cv = cv.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train_cv, y_train)\n",
        "print(\"CountVectorizer Accuracy:\", clf.score(X_test_cv, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO7raRqaEFRZ",
        "outputId": "78fedcdb-aba1-4eee-9ebf-30f0cb8c9662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorizer Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "print(\"TF-IDF Accuracy:\", clf.score(X_test_tfidf, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMAFahdqEKnV",
        "outputId": "64a4ba9d-eacf-4b40-860a-2ca77183b7ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_ngram = CountVectorizer(ngram_range=(1,3))\n",
        "X_train_cv3 = cv_ngram.fit_transform(X_train)\n",
        "X_test_cv3 = cv_ngram.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=2000)\n",
        "clf.fit(X_train_cv3, y_train)\n",
        "\n",
        "print(\"CountVectorizer (1–3 gram) Accuracy:\", clf.score(X_test_cv3, y_test))\n",
        "print(\"Number of features:\", X_train_cv3.shape[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xCU6h5DEO80",
        "outputId": "dfd91ff0-509a-44d2-bd51-ff6893624ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorizer (1–3 gram) Accuracy: 1.0\n",
            "Number of features: 80\n"
          ]
        }
      ]
    }
  ]
}